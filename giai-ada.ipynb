{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport math\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/emotion-detection-fer/train\" #train images directory\ntest_dir = \"../input/emotion-detection-fer/test\"   #test images directory\nsiz = 96\nbatch_siz = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(#rotation_range = 10,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   horizontal_flip = True,\n                                   rescale = 1./255,\n                                   #zoom_range = 0.2,\n                                   validation_split = 0.2\n                                  )\nvalidation_datagen = ImageDataGenerator(rescale = 1./255,\n                                        validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (siz, siz),\n                                                    batch_size = batch_siz,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (siz, siz),\n                                                              batch_size = batch_siz,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= tf.keras.models.Sequential(\n    [\n        Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(siz, siz,1)),\n        Conv2D(64,(3,3), padding='same', activation='relu' ),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(128,(5,5), padding='same', activation='relu'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Flatten(),\n        \n        Dense(512,activation = 'relu'),\n        BatchNormalization(),\n        Dropout(0.15),\n        \n        Dense(256, activation = 'relu'),\n        Dropout(0.15),\n        \n        Dense(128, activation = 'relu'),\n        Dropout(0.15),\n        \n        Dense(64, activation = 'relu'),\n        Dropout(0.15),\n        \n        Dense(32, activation = 'relu'),\n        Dropout(0.15),\n        \n        Dense(7, activation='softmax'),\n    ]\n)\nmodel.compile(\n    optimizer = Adam(lr=0.0001), \n    loss='categorical_crossentropy', \n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x = train_generator,epochs = 60, validation_data = validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mathematical model\n\n# PREVIOUS\n'''\nemotion = 2 #GET THE EMOTION FROM THE PICTURE, FOR EXAMPLE HAPPY: 2\ntimeSpentOnPicture = 60 #GET THE TIME SPENT ON THE PICTURE FROM THE APP, FOR EXAMPLE: 60\nscore = emotion * math.log10(timeSpentOnPicture)\nskipped = False #GET WETHER THE USER SKIPPED THE PICTURE OR NOT \nif skipped == True:\n    score -= emotion * math.log10(timeSpentOnPicture)\nelse:\n    score += emotion * math.log10(timeSpentOnPicture)\n'''\n\n# IMPROVED\n\nemotion = 2 #GET THE EMOTION FROM THE PICTURE, FOR EXAMPLE HAPPY: 2\ntimeSpentOnPicture = 60 #GET THE TIME SPENT ON THE PICTURE FROM THE APP, FOR EXAMPLE: 60\nscore = (emotion * math.log10(timeSpentOnPicture)) + 1\nskipped = False #GET WHETHER THE USER SKIPPED THE PICTURE OR NOT \nif skipped == True:\n    score += math.sqrt(score)\nelse:\n    score = math.sqrt(score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}